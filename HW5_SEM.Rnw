\documentclass{article}
\setlength\parindent{0pt}
\usepackage{fullpage}
\usepackage{dcolumn}

\begin{document}

\title{SEM\\ Longitudinal Data Analysis}
\author{Jackie Hayes}
\date{10/31/17}

<<tidy=TRUE>>=
rm(list=ls())
setwd("~/Dropbox/Classes/Longitudinal Data Analysis")
wgt <-read.table("weightslong.csv", sep=',', header=TRUE)
wgtwide <-read.table("weightsbyweek.csv", sep=',', header=TRUE)
dems <-read.table("agegender.csv", sep=',', header=TRUE)
dems$age.c<-dems$age-49.094
data <- merge(wgt, dems, by="ID")
data$gender[data$gender==1]<-0
data$gender[data$gender==2]<-1
library(tidyr)
library(dplyr)
library(plyr)
library(lubridate)
library(ggplot2)
library(lme4)
library(lavaan)
library(semPlot)
library(semTools)
@

\section{Question 1}
\textbf{\large{\textit{
Fit a measurement model to your constructs at one time point. Try out the different types of scaling discussed in class. What changes and what stays the same?
}}}

<<tidy=TRUE>>=
plan <-read.table("planQ.csv", sep=',', header=TRUE)
plans.model <- ' make  =~ makedietplans + planmealtimes + makeexerplan +  makeexertimes + maketempplan     
              follow =~ followdietplans + followmealtimes + followexerplan + followexertimes + followtempplan'
plansfit <- cfa(plans.model, data=plan)
summary(plansfit, fit.measures=TRUE, standardized=TRUE)
semPaths(plansfit, what = "std")

plansfit.2 <- cfa(plans.model, std.lv=TRUE, data=plan)
summary(plansfit.2, fit.measures=TRUE, standardized=TRUE)
semPaths(plansfit.2, what = "std")
#estimates change quite a bit, although the standardized values stay the same
#Fit indices also stay the same
@

\section{Question 2}
\textbf{\large{\textit{
What do the fit statistics say about your latent variable? Good/bad? Is your latent variable Just identified/saturdated, under identified or over identified?
}}}

<<tidy=TRUE>>=
#RMSEA and SRMR indicate poor fit
#CFI and TLI indicate poor fit
#model is overidentified 

#split diet and exercise plans
dietplans.model <- ' make  =~ makedietplans + planmealtimes + maketempplan     
              follow =~ followdietplans + followmealtimes + followtempplan'
dietplansfit.fix <- cfa(dietplans.model, std.lv=TRUE, data=plan)
summary(dietplansfit.fix, fit.measures=TRUE, standardized=TRUE)
semPaths(dietplansfit.fix, what = "std")
#does a little better
#SRMR indicates acceptable fit, RMSEA still way too high
#CFI and TLI still below .9
#overidentified

exerplans.model <- ' make  =~ makeexerplan +  makeexertimes     
              follow =~ followexerplan + followexertimes'
exerplansfit.fix <- cfa(exerplans.model, std.lv=TRUE, data=plan)
summary(exerplansfit.fix, fit.measures=TRUE, standardized=TRUE)
semPaths(exerplansfit.fix, what = "std")
#should be underidentified, but df is 6 or is it 1? which one to look at?  
#RMSEA (.67) way too high, SRMR (.032) is good - sooo diferent, why?
#CFI pretty close to .9, TLI still way off
@

\section{Question 3}
\textbf{\large{\textit{
Fit a longitudinal CFA model where you a) first correlate your latent factors across time and then b) a second model that predicts later times by a prevous time (ie auto regressive; t1 -> t2 -> t3). What are your conclusions? How does one differ from the other?
}}}

<<tidy=TRUE>>=
#make plans wide
#create subset of data and widen
plansub <- subset(plan, select = c(ID, week, makedietplans, planmealtimes, maketempplan))
library(reshape2)
plansub <- reshape(plansub, idvar = "ID", timevar = "week", direction = "wide")

longcfa <- '
plan1 =~ makedietplans.0 + planmealtimes.0 + maketempplan.0 
plan2 =~ makedietplans.10 + planmealtimes.10 + maketempplan.10 
plan3 =~ makedietplans.20 + planmealtimes.20 + maketempplan.20 
plan4 =~ makedietplans.30 + planmealtimes.30 + maketempplan.30 
plan5 =~ makedietplans.40 + planmealtimes.40 + maketempplan.40 

#correlated residuals across time
makedietplans.0 ~~ makedietplans.10 + makedietplans.20 + makedietplans.30 + makedietplans.40
makedietplans.10 ~~ makedietplans.20 + makedietplans.30 + makedietplans.40
makedietplans.20 ~~ makedietplans.30 + makedietplans.40
makedietplans.30 ~~ makedietplans.40
planmealtimes.0 ~~ planmealtimes.10 + planmealtimes.20 + planmealtimes.30 + planmealtimes.40
planmealtimes.10 ~~ planmealtimes.20 + planmealtimes.30 + planmealtimes.40
planmealtimes.20 ~~ planmealtimes.30 + planmealtimes.40
planmealtimes.30 ~~ planmealtimes.40
maketempplan.0 ~~ maketempplan.10 + maketempplan.20 + maketempplan.30 + maketempplan.40
maketempplan.10 ~~ maketempplan.20 + maketempplan.30 + maketempplan.40
maketempplan.20 ~~ maketempplan.30 + maketempplan.40
maketempplan.30 ~~ maketempplan.40
'

fit.long.cfa <- cfa(longcfa, data=plansub, std.lv=TRUE)

summary(fit.long.cfa, standardized=TRUE, fit.measures=TRUE)

#Getting "not positive definite" error
#CFI: 0.984
#TLI: 0.966
#Both above 0.95, which is good!
#RMSEA: 0.043
#SRMR: 0.081
#SRMR slightly over 0.08, but RMSEA well under - good fit!

#CROSS_LAGGED
long.cross <- '
## define latent variables
plan1 =~ makedietplans.0 + planmealtimes.0 + maketempplan.0
plan2 =~ makedietplans.10 + planmealtimes.10 + maketempplan.10
plan3 =~ makedietplans.20 + planmealtimes.20 + maketempplan.20
plan4 =~ makedietplans.30 + planmealtimes.30 + maketempplan.30
plan5 =~ makedietplans.40 + planmealtimes.40 + maketempplan.40

## free latent variances at later times (only set the scale once)
plan2 ~~ NA*plan2
plan3 ~~ NA*plan3
plan4 ~~ NA*plan4
plan5 ~~ NA*plan5

## directional regression paths
plan2 ~ plan1
plan3 ~ plan2
plan4 ~ plan3
plan5 ~ plan4

## correlated residuals across time
makedietplans.0 ~~ makedietplans.10 + makedietplans.20 + makedietplans.30 + makedietplans.40
makedietplans.10 ~~ makedietplans.20 + makedietplans.30 + makedietplans.40
makedietplans.20 ~~ makedietplans.30 + makedietplans.40
makedietplans.30 ~~ makedietplans.40
planmealtimes.0 ~~ planmealtimes.10 + planmealtimes.20 + planmealtimes.30 + planmealtimes.40
planmealtimes.10 ~~ planmealtimes.20 + planmealtimes.30 + planmealtimes.40
planmealtimes.20 ~~ planmealtimes.30 + planmealtimes.40
planmealtimes.30 ~~ planmealtimes.40
maketempplan.0 ~~ maketempplan.10 + maketempplan.20 + maketempplan.30 + maketempplan.40
maketempplan.10 ~~ maketempplan.20 + maketempplan.30 + maketempplan.40
maketempplan.20 ~~ maketempplan.30 + maketempplan.40
maketempplan.30 ~~ maketempplan.40
'

fit.long.cross <- sem(long.cross, data=plansub, std.lv=TRUE)

summary(fit.long.cross, standardized=TRUE, fit.measures=TRUE)
# Model not identified
# error that some lv variances are negative
@

\section{Question 4}
\textbf{\large{\textit{
Fit a longitdinal growth model in SEM and in HLM. Compare and contrast the differences.
}}}

<<tidy=TRUE>>=
#SEM
#intercept only model
SEMIntOnly <- ' i =~ 1*w_0 + 1*w_20 + 1*w_40 '
SEMIntOnlyfit <- growth(SEMIntOnly, missing = "ML", data = wgtwide)
summary(SEMIntOnlyfit)
semPaths(SEMIntOnlyfit, what = "std")

#intercept and fixed slope
SEMFixSlopes <- ' i =~ 1*w_0 + 1*w_20 + 1*w_40
                  s =~ 0*w_0 + 20*w_20 + 40*w_40

                  s ~~ 0*s' #fixed slopes, no variance
SEMFixSlopesfit <- growth(SEMFixSlopes, missing = "ML", data = wgtwide)
inspect(SEMFixSlopesfit, "cov.lv")
summary(SEMFixSlopesfit)
semPaths(SEMFixSlopesfit, what = "paths", whatLabels= "est", layout = "tree")
semPaths(SEMFixSlopesfit, what = "std")

#improve model fit?
anova(SEMIntOnlyfit, SEMFixSlopesfit)
#yes

#intercept and random slope
SEMRanSlopes <- ' i =~ 1*w_0 + 1*w_20 + 1*w_40
                  s =~ 0*w_0 + 20*w_20 + 40*w_40'
SEMRanSlopesfit <- growth(SEMRanSlopes, missing = "ML", data = wgtwide)
summary(SEMRanSlopesfit)
semPaths(SEMRanSlopesfit, what = "std")
#improve model fit?
anova(SEMFixSlopesfit, SEMRanSlopesfit)
#nope - random slope doesn't improve fit

#MLM
MLMIntOnly <- lmer(weight~ 1+ (1|ID), data=wgt)
summary(MLMIntOnly)
summary(SEMIntOnlyfit)
#Fixed effect similar 224 vs. 222
#Random effect similar variance
#Random effect residuals quite different - due to full inclusion of data in MLM?
MLMFixSlope <- lmer(weight~ 1+ wave + (1|ID), data=wgt)
summary(MLMFixSlope)
summary(SEMFixSlopesfit)
#Fixed and random effects similar
@

\section{Question 5}
\textbf{\large{\textit{
Constrain the residual variances to be equal. Does this change the fit of your model?
}}}

<<tidy=TRUE>>=
SEMFixSlopesres <- ' i =~ 1*w_0 + 1*w_20 + 1*w_40
                  s =~ 0*w_0 + 20*w_20 + 40*w_40

                  s ~~ 0*s #fixed slopes, no variance
                  w_0 ~~ a*w_0
                  w_20 ~~ a*w_20
                  w_40 ~~ a*w_40 #residuals are equal to each other'
SEMFixSlopesfitres <- growth(SEMFixSlopesres, missing = "ML", data = wgtwide)
summary(SEMFixSlopesfitres)
SEMFixSlopesfit <- growth(SEMFixSlopes, missing = "ML", data = wgtwide)
summary(SEMFixSlopesfit)

anova(SEMFixSlopesfit,SEMFixSlopesfitres)
#Fixing residuals to equal each other makes the model significantly worse
@

\section{Question 6}
\textbf{\large{\textit{
Contrain your slope to be fixed, not random. How does this change your model?
}}}

<<tidy=TRUE>>=
#see above
anova(SEMFixSlopesfit, SEMRanSlopesfit)
#Model produces similar results with fixed and random slopes
@

\section{Question 7}
\textbf{\large{\textit{
Change the time metric in your SEM growth model. How does that change your estimates? Does it change your fit statistics?
}}}

<<tidy=TRUE>>=
SEMFixSlopestime <- ' i =~ 1*w_0 + 1*w_20 + 1*w_40
                  s =~ 0*w_0 + 1*w_20 + 2*w_40

                  s ~~ 0*s #fixed slopes, no variance'
SEMFixSlopesfittime <- growth(SEMFixSlopestime, missing = "ML", data = wgtwide)
summary(SEMFixSlopesfittime)
summary(SEMFixSlopesfit)
#same - same distance between variables.

#Different intercept
SEMFixSlopesint <- ' i =~ 1*w_0 + 1*w_20 + 1*w_40
                  s =~ -20*w_0 + 0*w_20 + 20*w_40

                  s ~~ 0*s #fixed slopes, no variance'
SEMFixSlopesfitint <- growth(SEMFixSlopesint, missing = "ML", data = wgtwide)
summary(SEMFixSlopesfitint)
#intercept different, lower, at week 20, average weight would be lower
#random effect of intercept is lower
#slope and residual variance the same
semPaths(SEMFixSlopesfitint, what = "std")
@

\section{Question 8}
\textbf{\large{\textit{
Try a different type of estimation (see lavaan tutorial for details). How does that change your model?
}}}

<<tidy=TRUE>>=
SEMFixSlopesMLM <- ' i =~ 1*w_0 + 1*w_20 + 1*w_40
                  s =~ 0*w_0 + 20*w_20 + 40*w_40

                  s ~~ 0*s #fixed slopes, no variance'
SEMFixSlopesfitMLM <- growth(SEMFixSlopesMLM, estimator = "MLM", data = wgtwide)
summary(SEMFixSlopesfitMLM)
summary(SEMFixSlopesfit)
#lower intercept, slower rate of change
semPaths(SEMFixSlopesfitMLM, what="std")
@

\section{Question 9}
\textbf{\large{\textit{
Provide semplots for each of the models
}}}

<<tidy=TRUE>>=
#Graphs provided throughout
@

\section{Question 10}
\textbf{\large{\textit{
Test measurement invariance across time for your construct. Can you run growth models? If there is evidence of non-invariance, what seems to be the problem?
}}}

<<tidy=TRUE>>=
#CONFIGURAL
config <- '
#Define latent variables
plan1 =~ makedietplans.0 + planmealtimes.0 + maketempplan.0
plan2 =~ makedietplans.10 + planmealtimes.10 + maketempplan.10
plan3 =~ makedietplans.20 + planmealtimes.20 + maketempplan.20
plan4 =~ makedietplans.30 + planmealtimes.30 + maketempplan.30
plan5 =~ makedietplans.40 + planmealtimes.40 + maketempplan.40

#correlated residuals across time
makedietplans.0 ~~ makedietplans.10 + makedietplans.20 + makedietplans.30 + makedietplans.40
makedietplans.10 ~~ makedietplans.20 + makedietplans.30 + makedietplans.40
makedietplans.20 ~~ makedietplans.30 + makedietplans.40
makedietplans.30 ~~ makedietplans.40
planmealtimes.0 ~~ planmealtimes.10 + planmealtimes.20 + planmealtimes.30 + planmealtimes.40
planmealtimes.10 ~~ planmealtimes.20 + planmealtimes.30 + planmealtimes.40
planmealtimes.20 ~~ planmealtimes.30 + planmealtimes.40
planmealtimes.30 ~~ planmealtimes.40
maketempplan.0 ~~ maketempplan.10 + maketempplan.20 + maketempplan.30 + maketempplan.40
maketempplan.10 ~~ maketempplan.20 + maketempplan.30 + maketempplan.40
maketempplan.20 ~~ maketempplan.30 + maketempplan.40
maketempplan.30 ~~ maketempplan.40
'

config <- cfa(config, data=plansub, meanstructure=TRUE, std.lv=TRUE)

summary(config, standardized=TRUE, fit.measures=TRUE)

#CFI and TLI good

#WEAK
weak <- '
plan1 =~ L1*makedietplans.0 + L2*planmealtimes.0 + L3*maketempplan.0
plan2 =~ L1*makedietplans.10 + L2*planmealtimes.10 + L3*maketempplan.10
plan3 =~ L1*makedietplans.20 + L2*planmealtimes.20 + L3*maketempplan.20
plan4 =~ L1*makedietplans.30 + L2*planmealtimes.30 + L3*maketempplan.30
plan5 =~ L1*makedietplans.40 + L2*planmealtimes.40 + L3*maketempplan.40

#free latent variances at later times (only set the scale once)
plan2 ~~ NA*plan2
plan3 ~~ NA*plan3
plan4 ~~ NA*plan4
plan5 ~~ NA*plan5

#correlated residuals across time
makedietplans.0 ~~ makedietplans.10 + makedietplans.20 + makedietplans.30 + makedietplans.40
makedietplans.10 ~~ makedietplans.20 + makedietplans.30 + makedietplans.40
makedietplans.20 ~~ makedietplans.30 + makedietplans.40
makedietplans.30 ~~ makedietplans.40
planmealtimes.0 ~~ planmealtimes.10 + planmealtimes.20 + planmealtimes.30 + planmealtimes.40
planmealtimes.10 ~~ planmealtimes.20 + planmealtimes.30 + planmealtimes.40
planmealtimes.20 ~~ planmealtimes.30 + planmealtimes.40
planmealtimes.30 ~~ planmealtimes.40
maketempplan.0 ~~ maketempplan.10 + maketempplan.20 + maketempplan.30 + maketempplan.40
maketempplan.10 ~~ maketempplan.20 + maketempplan.30 + maketempplan.40
maketempplan.20 ~~ maketempplan.30 + maketempplan.40
maketempplan.30 ~~ maketempplan.40
'
weak <- cfa(weak, data=plansub, meanstructure=TRUE, std.lv=TRUE)

summary(weak, standardized=TRUE, fit.measures=TRUE)
#Get not positive definite error

anova(config, weak)

#STRONG
strong <- '
plan1 =~ L1*makedietplans.0 + L2*planmealtimes.0 + L3*maketempplan.0
plan2 =~ L1*makedietplans.10 + L2*planmealtimes.10 + L3*maketempplan.10
plan3 =~ L1*makedietplans.20 + L2*planmealtimes.20 + L3*maketempplan.20
plan4 =~ L1*makedietplans.30 + L2*planmealtimes.30 + L3*maketempplan.30
plan5 =~ L1*makedietplans.40 + L2*planmealtimes.40 + L3*maketempplan.40

#free latent variances at later times (only set the scale once)
plan2 ~~ NA*plan2
plan3 ~~ NA*plan3
plan4 ~~ NA*plan4
plan5 ~~ NA*plan5

#correlated residuals across time
makedietplans.0 ~~ makedietplans.10 + makedietplans.20 + makedietplans.30 + makedietplans.40
makedietplans.10 ~~ makedietplans.20 + makedietplans.30 + makedietplans.40
makedietplans.20 ~~ makedietplans.30 + makedietplans.40
makedietplans.30 ~~ makedietplans.40
planmealtimes.0 ~~ planmealtimes.10 + planmealtimes.20 + planmealtimes.30 + planmealtimes.40
planmealtimes.10 ~~ planmealtimes.20 + planmealtimes.30 + planmealtimes.40
planmealtimes.20 ~~ planmealtimes.30 + planmealtimes.40
planmealtimes.30 ~~ planmealtimes.40
maketempplan.0 ~~ maketempplan.10 + maketempplan.20 + maketempplan.30 + maketempplan.40
maketempplan.10 ~~ maketempplan.20 + maketempplan.30 + maketempplan.40
maketempplan.20 ~~ maketempplan.30 + maketempplan.40
maketempplan.30 ~~ maketempplan.40

## constrain intercepts across time
makedietplans.0 ~ t1*1
planmealtimes.0 ~ t2*1
maketempplan.0 ~ t3*1

makedietplans.10 ~ t1*1
planmealtimes.10 ~ t2*1
maketempplan.10 ~ t3*1

makedietplans.20 ~ t1*1
planmealtimes.20 ~ t2*1
maketempplan.20 ~ t3*1

makedietplans.30 ~ t1*1
planmealtimes.30 ~ t2*1
maketempplan.30 ~ t3*1

makedietplans.40 ~ t1*1
planmealtimes.40 ~ t2*1
maketempplan.40 ~ t3*1

## free latent means at later times (only set the scale once)
plan2 ~ NA*1
plan3 ~ NA*1
plan4 ~ NA*1
plan5 ~ NA*1
'

strong <- cfa(strong, data=plansub, meanstructure=TRUE, std.lv=TRUE)

summary(strong, standardized=TRUE, fit.measures=TRUE)
#Still getting the not positive definite error

#CFIs of models
fitmeasures(config)['cfi']
fitmeasures(weak)['cfi']
fitmeasures(strong)['cfi']
#Decreasing by more than .01 with each model

#Comparison of models with anova function
anova(config, weak)
anova(weak, strong)
#also show significant differences

#There is evidence of non-invariance. If I were to speculate, the reason why the invariance is occurring is because the 
#questionnaire asks about planning. Participants completed at baseline, potentially before having a good indication of
#what meal planning really was. Then, across the program, it's possible the concept of meal planning changed as people
#got good at it and it required less effort.
@

\section{Question 11}
\textbf{\large{\textit{
Fit a second order growth model. Compare and contrast the estimates with the normal latent growth model.
}}}

<<tidy=TRUE>>=
sec.order <- '
## define latent variables
plan1 =~ NA*makedietplans.0 + L1*makedietplans.0 + L2*planmealtimes.0 + L3*maketempplan.0
plan2 =~ NA*makedietplans.10 + L1*makedietplans.10 + L2*planmealtimes.10 + L3*maketempplan.10
plan3 =~ NA*makedietplans.20 + L1*makedietplans.20 + L2*planmealtimes.20 + L3*maketempplan.20
plan4 =~ NA*makedietplans.30 + L1*makedietplans.30 + L2*planmealtimes.30 + L3*maketempplan.30
plan5 =~ NA*makedietplans.40 + L1*makedietplans.40 + L2*planmealtimes.40 + L3*maketempplan.40

## constrain intercepts across time
makedietplans.0 ~ t1*1
planmealtimes.0 ~ t2*1
maketempplan.0 ~ t3*1

makedietplans.10 ~ t1*1
planmealtimes.10 ~ t2*1
maketempplan.10 ~ t3*1

makedietplans.20 ~ t1*1
planmealtimes.20 ~ t2*1
maketempplan.20 ~ t3*1

makedietplans.30 ~ t1*1
planmealtimes.30 ~ t2*1
maketempplan.30 ~ t3*1

makedietplans.40 ~ t1*1
planmealtimes.40 ~ t2*1
maketempplan.40 ~ t3*1

## correlated residuals across time
makedietplans.0 ~~ makedietplans.10 + makedietplans.20 + makedietplans.30 + makedietplans.40
makedietplans.10 ~~ makedietplans.20 + makedietplans.30 + makedietplans.40
makedietplans.20 ~~ makedietplans.30 + makedietplans.40
makedietplans.30 ~~ makedietplans.40
planmealtimes.0 ~~ planmealtimes.10 + planmealtimes.20 + planmealtimes.30 + planmealtimes.40
planmealtimes.10 ~~ planmealtimes.20 + planmealtimes.30 + planmealtimes.40
planmealtimes.20 ~~ planmealtimes.30 + planmealtimes.40
planmealtimes.30 ~~ planmealtimes.40
maketempplan.0 ~~ maketempplan.10 + maketempplan.20 + maketempplan.30 + maketempplan.40
maketempplan.10 ~~ maketempplan.20 + maketempplan.30 + maketempplan.40
maketempplan.20 ~~ maketempplan.30 + maketempplan.40
maketempplan.30 ~~ maketempplan.40


## latent variable intercepts
plan1 ~ 0*1
plan2 ~ 0*1
plan3 ~ 0*1
plan4 ~ 0*1
plan5 ~ 0*1

#model constraints for effect coding
## loadings must average to 1
L1 == 3 - L2 - L3
## means must average to 0
t1 == 0 - t2 - t3

i =~ 1*plan1 + 1*plan2 + 1*plan3 + 1*plan4 + 1*plan5
s =~ 0*plan1 + 10*plan2 + 20*plan3 + 30*plan4 + 40*plan5
'

fit.sec.order <- growth(sec.order, data=plansub, missing = "ML")
summary(fit.sec.order, fit.measures=TRUE)

#Normal latent growth model for planning data
#create variables
plansub$plan1 <- plansub$makedietplans.0 + plansub$planmealtimes.0 + plansub$maketempplan.0
plansub$plan2 <- plansub$makedietplans.10 + plansub$planmealtimes.10 + plansub$maketempplan.10
plansub$plan3 <- plansub$makedietplans.20 + plansub$planmealtimes.20 + plansub$maketempplan.20
plansub$plan4 <- plansub$makedietplans.30 + plansub$planmealtimes.30 + plansub$maketempplan.30
plansub$plan5 <- plansub$makedietplans.40 + plansub$planmealtimes.40 + plansub$maketempplan.40

#intercept and fixed slope
SEMFixSlopesplan <- ' i =~ 1*plan1 + 1*plan2 + 1*plan3 + 1*plan4 + 1*plan5
                  s =~ 0*plan1 + 10*plan2 + 20*plan3 + 30*plan4 + 40*plan5
                  s ~~ 0*s  
                  i ~~ 0*s' #fixed slopes, no variance and specify no correlation between fixed slope and intercept
SEMFixSlopesplanfit <- growth(SEMFixSlopesplan, missing = "ML", data = plansub)
inspect(SEMFixSlopesplanfit, "cov.lv")
summary(SEMFixSlopesplanfit)
# not getting fit indices - not positive definite error

#intercept and random slope
SEMRanSlopesplan <- ' i =~ 1*plan1 + 1*plan2 + 1*plan3 + 1*plan4 + 1*plan5
                  s =~ 0*plan1 + 10*plan2 + 20*plan3 + 30*plan4 + 40*plan5
                  i ~~ 0*s'
SEMRanSlopesplanfit <- growth(SEMRanSlopesplan, missing = "ML", data = plansub)
inspect(SEMRanSlopesplanfit, "cov.lv")
summary(SEMRanSlopesplanfit)

#improve model fit?
anova(SEMFixSlopesplanfit, SEMRanSlopesplanfit)
#nope - random slope doesn't improve fit

#can't get fit indices in the normal one to compare to the second order one
@

\section{Question 12}
\textbf{\large{\textit{
Fit a series of multiple group models. Constrain some parameters and compare the fit.
}}}

<<tidy=TRUE>>=
#Adding Gender to dataset
plan1<- dplyr::left_join(plan, dems, by="ID")

#Multiple Groups
group1 <- ' make  =~ makedietplans + planmealtimes + maketempplan     
follow =~ followdietplans + followmealtimes + followtempplan

make ~~ 1*make
follow ~~ 1*follow

make ~~ follow
'
fit.group.1 <- cfa(group1, data=plan1, std.lv=TRUE, group = "gender")

summary(fit.group.1, standardized=TRUE, fit.measures=TRUE)

#Multiple Groups - Constraints
group2 <- ' make  =~ c(L1,L1)*makedietplans + c(L2,L2)*planmealtimes + c(L3,L3)*maketempplan     
follow =~ followdietplans + followmealtimes + followtempplan

make ~~ 1*make
follow ~~ 1*follow

make ~~ follow
'
fit.group.2 <- cfa(group2, data=plan1, std.lv=TRUE, group = "gender")

summary(fit.group.2, standardized=TRUE, fit.measures=TRUE)

anova(fit.group.1,fit.group.2)
#no improvements with constraints

#Keeping Loading and Intercepts the Same
group3 <- ' make  =~ makedietplans + planmealtimes + maketempplan     
follow =~ followdietplans + followmealtimes + followtempplan

make ~~ 1*make
follow ~~ 1*follow

make ~~ follow
'
fit.group.3 <- cfa(group3, data=plan1, std.lv=TRUE, group = "gender", group.equal=c("loadings", "intercepts"))

summary(fit.group.3, standardized=TRUE, fit.measures=TRUE)

anova(fit.group.1,fit.group.3)
#Setting loadings and intercepts equal across groups makes fit worse
@

\end{document}